{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Prayag\n",
      "[nltk_data]     Chawla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Prayag\n",
      "[nltk_data]     Chawla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Prayag\n",
      "[nltk_data]     Chawla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input,LSTM,Embedding,Dense,Concatenate,Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Reviews.csv\",nrows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1SP2KVKFXXRU1</td>\n",
       "      <td>David C. Sullivan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340150400</td>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A3JRGQVEQN31IQ</td>\n",
       "      <td>Pamela G. Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1336003200</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>B000E7L2R4</td>\n",
       "      <td>A1MZYO9TZK0BBI</td>\n",
       "      <td>R. James</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1322006400</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>B00171APVA</td>\n",
       "      <td>A21BT40VZCCYT4</td>\n",
       "      <td>Carol A. Reed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>B0001PB9FE</td>\n",
       "      <td>A3HDKO7OW0QNK4</td>\n",
       "      <td>Canadian Fan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1107820800</td>\n",
       "      <td>The Best Hot Sauce in the World</td>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>B0009XLVG0</td>\n",
       "      <td>A2725IB4YY9JEB</td>\n",
       "      <td>A Poeng \"SparkyGoHome\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1282867200</td>\n",
       "      <td>My cats LOVE this \"diet\" food better than thei...</td>\n",
       "      <td>One of my boys needed to lose some weight and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>B0009XLVG0</td>\n",
       "      <td>A327PCT23YH90</td>\n",
       "      <td>LT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1339545600</td>\n",
       "      <td>My Cats Are Not Fans of the New Food</td>\n",
       "      <td>My cats have been happily eating Felidae Plati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A18ECVX2RJ7HUE</td>\n",
       "      <td>willie \"roadie\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1288915200</td>\n",
       "      <td>fresh and greasy!</td>\n",
       "      <td>good flavor! these came securely packed... the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A2MUGFV2TDQ47K</td>\n",
       "      <td>Lynrie \"Oh HELL no\"</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1268352000</td>\n",
       "      <td>Strawberry Twizzlers - Yummy</td>\n",
       "      <td>The Strawberry Twizzlers are my guilty pleasur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A1CZX3CP8IKQIJ</td>\n",
       "      <td>Brian A. Lee</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1262044800</td>\n",
       "      <td>Lots of twizzlers, just what you expect.</td>\n",
       "      <td>My daughter loves twizzlers and this shipment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A3KLWF6WQ5BNYO</td>\n",
       "      <td>Erica Neathery</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1348099200</td>\n",
       "      <td>poor taste</td>\n",
       "      <td>I love eating them and they are good for watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>AFKW14U97Z6QO</td>\n",
       "      <td>Becca</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1345075200</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>I am very satisfied with my Twizzler purchase....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A2A9X58G2GTBLP</td>\n",
       "      <td>Wolfee1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1324598400</td>\n",
       "      <td>GREAT SWEET CANDY!</td>\n",
       "      <td>Twizzlers, Strawberry my childhood favorite ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A3IV7CL2C13K2U</td>\n",
       "      <td>Greg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1318032000</td>\n",
       "      <td>Home delivered twizlers</td>\n",
       "      <td>Candy was delivered very fast and was purchase...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id   ProductId          UserId                      ProfileName  \\\n",
       "0    1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1    2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2    3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3    4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4    5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5    6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "6    7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
       "7    8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n",
       "8    9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n",
       "9   10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n",
       "10  11  B0001PB9FE  A3HDKO7OW0QNK4                     Canadian Fan   \n",
       "11  12  B0009XLVG0  A2725IB4YY9JEB           A Poeng \"SparkyGoHome\"   \n",
       "12  13  B0009XLVG0   A327PCT23YH90                               LT   \n",
       "13  14  B001GVISJM  A18ECVX2RJ7HUE                  willie \"roadie\"   \n",
       "14  15  B001GVISJM  A2MUGFV2TDQ47K              Lynrie \"Oh HELL no\"   \n",
       "15  16  B001GVISJM  A1CZX3CP8IKQIJ                     Brian A. Lee   \n",
       "16  17  B001GVISJM  A3KLWF6WQ5BNYO                   Erica Neathery   \n",
       "17  18  B001GVISJM   AFKW14U97Z6QO                            Becca   \n",
       "18  19  B001GVISJM  A2A9X58G2GTBLP                          Wolfee1   \n",
       "19  20  B001GVISJM  A3IV7CL2C13K2U                             Greg   \n",
       "\n",
       "    HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                      1                       1      5  1303862400   \n",
       "1                      0                       0      1  1346976000   \n",
       "2                      1                       1      4  1219017600   \n",
       "3                      3                       3      2  1307923200   \n",
       "4                      0                       0      5  1350777600   \n",
       "5                      0                       0      4  1342051200   \n",
       "6                      0                       0      5  1340150400   \n",
       "7                      0                       0      5  1336003200   \n",
       "8                      1                       1      5  1322006400   \n",
       "9                      0                       0      5  1351209600   \n",
       "10                     1                       1      5  1107820800   \n",
       "11                     4                       4      5  1282867200   \n",
       "12                     1                       1      1  1339545600   \n",
       "13                     2                       2      4  1288915200   \n",
       "14                     4                       5      5  1268352000   \n",
       "15                     4                       5      5  1262044800   \n",
       "16                     0                       0      2  1348099200   \n",
       "17                     0                       0      5  1345075200   \n",
       "18                     0                       0      5  1324598400   \n",
       "19                     0                       0      5  1318032000   \n",
       "\n",
       "                                              Summary  \\\n",
       "0                               Good Quality Dog Food   \n",
       "1                                   Not as Advertised   \n",
       "2                               \"Delight\" says it all   \n",
       "3                                      Cough Medicine   \n",
       "4                                         Great taffy   \n",
       "5                                          Nice Taffy   \n",
       "6       Great!  Just as good as the expensive brands!   \n",
       "7                              Wonderful, tasty taffy   \n",
       "8                                          Yay Barley   \n",
       "9                                    Healthy Dog Food   \n",
       "10                    The Best Hot Sauce in the World   \n",
       "11  My cats LOVE this \"diet\" food better than thei...   \n",
       "12               My Cats Are Not Fans of the New Food   \n",
       "13                                  fresh and greasy!   \n",
       "14                       Strawberry Twizzlers - Yummy   \n",
       "15           Lots of twizzlers, just what you expect.   \n",
       "16                                         poor taste   \n",
       "17                                           Love it!   \n",
       "18                                 GREAT SWEET CANDY!   \n",
       "19                            Home delivered twizlers   \n",
       "\n",
       "                                                 Text  \n",
       "0   I have bought several of the Vitality canned d...  \n",
       "1   Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2   This is a confection that has been around a fe...  \n",
       "3   If you are looking for the secret ingredient i...  \n",
       "4   Great taffy at a great price.  There was a wid...  \n",
       "5   I got a wild hair for taffy and ordered this f...  \n",
       "6   This saltwater taffy had great flavors and was...  \n",
       "7   This taffy is so good.  It is very soft and ch...  \n",
       "8   Right now I'm mostly just sprouting this so my...  \n",
       "9   This is a very healthy dog food. Good for thei...  \n",
       "10  I don't know if it's the cactus or the tequila...  \n",
       "11  One of my boys needed to lose some weight and ...  \n",
       "12  My cats have been happily eating Felidae Plati...  \n",
       "13  good flavor! these came securely packed... the...  \n",
       "14  The Strawberry Twizzlers are my guilty pleasur...  \n",
       "15  My daughter loves twizzlers and this shipment ...  \n",
       "16  I love eating them and they are good for watch...  \n",
       "17  I am very satisfied with my Twizzler purchase....  \n",
       "18  Twizzlers, Strawberry my childhood favorite ca...  \n",
       "19  Candy was delivered very fast and was purchase...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['Text'],inplace=True)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "input_data = df.loc[:,'Text']\n",
    "target_data = df.loc[:,'Summary']\n",
    "contractions=pickle.load(open(\"./contractions.pkl\",\"rb\"))['contractions']\n",
    "#initialize stop words and LancasterStemmer\n",
    "stop_words=set(stopwords.words('english'))\n",
    "stemm=LancasterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1SP2KVKFXXRU1</td>\n",
       "      <td>David C. Sullivan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340150400</td>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A3JRGQVEQN31IQ</td>\n",
       "      <td>Pamela G. Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1336003200</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>B000E7L2R4</td>\n",
       "      <td>A1MZYO9TZK0BBI</td>\n",
       "      <td>R. James</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1322006400</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>B00171APVA</td>\n",
       "      <td>A21BT40VZCCYT4</td>\n",
       "      <td>Carol A. Reed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>B0001PB9FE</td>\n",
       "      <td>A3HDKO7OW0QNK4</td>\n",
       "      <td>Canadian Fan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1107820800</td>\n",
       "      <td>The Best Hot Sauce in the World</td>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>B0009XLVG0</td>\n",
       "      <td>A2725IB4YY9JEB</td>\n",
       "      <td>A Poeng \"SparkyGoHome\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1282867200</td>\n",
       "      <td>My cats LOVE this \"diet\" food better than thei...</td>\n",
       "      <td>One of my boys needed to lose some weight and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>B0009XLVG0</td>\n",
       "      <td>A327PCT23YH90</td>\n",
       "      <td>LT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1339545600</td>\n",
       "      <td>My Cats Are Not Fans of the New Food</td>\n",
       "      <td>My cats have been happily eating Felidae Plati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A18ECVX2RJ7HUE</td>\n",
       "      <td>willie \"roadie\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1288915200</td>\n",
       "      <td>fresh and greasy!</td>\n",
       "      <td>good flavor! these came securely packed... the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A2MUGFV2TDQ47K</td>\n",
       "      <td>Lynrie \"Oh HELL no\"</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1268352000</td>\n",
       "      <td>Strawberry Twizzlers - Yummy</td>\n",
       "      <td>The Strawberry Twizzlers are my guilty pleasur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A1CZX3CP8IKQIJ</td>\n",
       "      <td>Brian A. Lee</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1262044800</td>\n",
       "      <td>Lots of twizzlers, just what you expect.</td>\n",
       "      <td>My daughter loves twizzlers and this shipment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A3KLWF6WQ5BNYO</td>\n",
       "      <td>Erica Neathery</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1348099200</td>\n",
       "      <td>poor taste</td>\n",
       "      <td>I love eating them and they are good for watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>AFKW14U97Z6QO</td>\n",
       "      <td>Becca</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1345075200</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>I am very satisfied with my Twizzler purchase....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A2A9X58G2GTBLP</td>\n",
       "      <td>Wolfee1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1324598400</td>\n",
       "      <td>GREAT SWEET CANDY!</td>\n",
       "      <td>Twizzlers, Strawberry my childhood favorite ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A3IV7CL2C13K2U</td>\n",
       "      <td>Greg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1318032000</td>\n",
       "      <td>Home delivered twizlers</td>\n",
       "      <td>Candy was delivered very fast and was purchase...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id   ProductId          UserId                      ProfileName  \\\n",
       "0    1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1    2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2    3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3    4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4    5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5    6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "6    7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
       "7    8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n",
       "8    9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n",
       "9   10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n",
       "10  11  B0001PB9FE  A3HDKO7OW0QNK4                     Canadian Fan   \n",
       "11  12  B0009XLVG0  A2725IB4YY9JEB           A Poeng \"SparkyGoHome\"   \n",
       "12  13  B0009XLVG0   A327PCT23YH90                               LT   \n",
       "13  14  B001GVISJM  A18ECVX2RJ7HUE                  willie \"roadie\"   \n",
       "14  15  B001GVISJM  A2MUGFV2TDQ47K              Lynrie \"Oh HELL no\"   \n",
       "15  16  B001GVISJM  A1CZX3CP8IKQIJ                     Brian A. Lee   \n",
       "16  17  B001GVISJM  A3KLWF6WQ5BNYO                   Erica Neathery   \n",
       "17  18  B001GVISJM   AFKW14U97Z6QO                            Becca   \n",
       "18  19  B001GVISJM  A2A9X58G2GTBLP                          Wolfee1   \n",
       "19  20  B001GVISJM  A3IV7CL2C13K2U                             Greg   \n",
       "\n",
       "    HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                      1                       1      5  1303862400   \n",
       "1                      0                       0      1  1346976000   \n",
       "2                      1                       1      4  1219017600   \n",
       "3                      3                       3      2  1307923200   \n",
       "4                      0                       0      5  1350777600   \n",
       "5                      0                       0      4  1342051200   \n",
       "6                      0                       0      5  1340150400   \n",
       "7                      0                       0      5  1336003200   \n",
       "8                      1                       1      5  1322006400   \n",
       "9                      0                       0      5  1351209600   \n",
       "10                     1                       1      5  1107820800   \n",
       "11                     4                       4      5  1282867200   \n",
       "12                     1                       1      1  1339545600   \n",
       "13                     2                       2      4  1288915200   \n",
       "14                     4                       5      5  1268352000   \n",
       "15                     4                       5      5  1262044800   \n",
       "16                     0                       0      2  1348099200   \n",
       "17                     0                       0      5  1345075200   \n",
       "18                     0                       0      5  1324598400   \n",
       "19                     0                       0      5  1318032000   \n",
       "\n",
       "                                              Summary  \\\n",
       "0                               Good Quality Dog Food   \n",
       "1                                   Not as Advertised   \n",
       "2                               \"Delight\" says it all   \n",
       "3                                      Cough Medicine   \n",
       "4                                         Great taffy   \n",
       "5                                          Nice Taffy   \n",
       "6       Great!  Just as good as the expensive brands!   \n",
       "7                              Wonderful, tasty taffy   \n",
       "8                                          Yay Barley   \n",
       "9                                    Healthy Dog Food   \n",
       "10                    The Best Hot Sauce in the World   \n",
       "11  My cats LOVE this \"diet\" food better than thei...   \n",
       "12               My Cats Are Not Fans of the New Food   \n",
       "13                                  fresh and greasy!   \n",
       "14                       Strawberry Twizzlers - Yummy   \n",
       "15           Lots of twizzlers, just what you expect.   \n",
       "16                                         poor taste   \n",
       "17                                           Love it!   \n",
       "18                                 GREAT SWEET CANDY!   \n",
       "19                            Home delivered twizlers   \n",
       "\n",
       "                                                 Text  \n",
       "0   I have bought several of the Vitality canned d...  \n",
       "1   Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2   This is a confection that has been around a fe...  \n",
       "3   If you are looking for the secret ingredient i...  \n",
       "4   Great taffy at a great price.  There was a wid...  \n",
       "5   I got a wild hair for taffy and ordered this f...  \n",
       "6   This saltwater taffy had great flavors and was...  \n",
       "7   This taffy is so good.  It is very soft and ch...  \n",
       "8   Right now I'm mostly just sprouting this so my...  \n",
       "9   This is a very healthy dog food. Good for thei...  \n",
       "10  I don't know if it's the cactus or the tequila...  \n",
       "11  One of my boys needed to lose some weight and ...  \n",
       "12  My cats have been happily eating Felidae Plati...  \n",
       "13  good flavor! these came securely packed... the...  \n",
       "14  The Strawberry Twizzlers are my guilty pleasur...  \n",
       "15  My daughter loves twizzlers and this shipment ...  \n",
       "16  I love eating them and they are good for watch...  \n",
       "17  I am very satisfied with my Twizzler purchase....  \n",
       "18  Twizzlers, Strawberry my childhood favorite ca...  \n",
       "19  Candy was delivered very fast and was purchase...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abspath = pathlib.Path(contractions).absolute()\n",
    "# with open(str(abspath), 'wb') as f:\n",
    "#     pickle.dump(\"thing_to_pickle\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_words=[]\n",
    "target_words=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions= pickle.load(open(\"contractions.pkl\",\"rb\"))['contractions']\n",
    "stop_words=set(stopwords.words('english'))\n",
    "stemm=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(texts,src):\n",
    "  #remove the html tags from the website\n",
    "  texts = BeautifulSoup(texts, \"lxml\").text\n",
    "  #tokenize the text into words \n",
    "  words=word_tokenize(texts.lower())\n",
    "  #filter words which contains \\ \n",
    "  #integers or their length is less than or equal to 3\n",
    "  words= list(filter(lambda w:(w.isalpha() and len(w)>=3),words))\n",
    "  words= [contractions[w] if w in contractions else w for w in words ]\n",
    "  #stem the words to their root word and filter stop words\n",
    "  if src==\"inputs\":\n",
    "    words= [stemm.stem(w) for w in words if w not in stop_words]\n",
    "  else:\n",
    "    words= [w for w in words if w not in stop_words]\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contraction file to expand shortened words\n",
    "for in_txt,tr_txt in zip(input_data,target_data):\n",
    "  in_words= clean(in_txt,\"inputs\")\n",
    "  input_texts+= [' '.join(in_words)]\n",
    "  input_words+= in_words\n",
    "  #add 'sos' at start and 'eos' at end of text\n",
    "  tr_words= clean(\"sos \"+tr_txt+\" eos\",\"target\")\n",
    "  target_texts+= [' '.join(tr_words)]\n",
    "  target_words+= tr_words\n",
    "\n",
    "# print(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of input words :  311\n",
      "number of target words :  46\n",
      "maximum input length :  64\n",
      "maximum target length :  18\n"
     ]
    }
   ],
   "source": [
    "input_words = sorted(list(set(input_words)))\n",
    "target_words = sorted(list(set(target_words)))\n",
    "num_in_words = len(input_words) #total number of input words\n",
    "num_tr_words = len(target_words) #total number of target words\n",
    "  \n",
    "max_in_len = mode([len(i) for i in input_texts])\n",
    "max_tr_len = mode([len(i) for i in target_texts])\n",
    " \n",
    "print(\"number of input words : \",num_in_words)\n",
    "print(\"number of target words : \",num_tr_words)\n",
    "print(\"maximum input length : \",max_in_len)\n",
    "print(\"maximum target length : \",max_tr_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(input_texts,target_texts,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tokenizer = Tokenizer()\n",
    "in_tokenizer.fit_on_texts(x_train)\n",
    "tr_tokenizer = Tokenizer()\n",
    "tr_tokenizer.fit_on_texts(y_train)\n",
    " \n",
    "#convert text into sequence of integers\n",
    "#where the integer will be the index of that word\n",
    "x_train= in_tokenizer.texts_to_sequences(x_train) \n",
    "y_train= tr_tokenizer.texts_to_sequences(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad array of 0's if the length is less than the maximum length \n",
    "en_in_data= pad_sequences(x_train,  maxlen=max_in_len, padding='post') \n",
    "dec_data= pad_sequences(y_train,  maxlen=max_tr_len, padding='post')\n",
    " \n",
    "#decoder input data will not include the last word \n",
    "#i.e. 'eos' in decoder input data\n",
    "dec_in_data = dec_data[:,:-1]\n",
    "#decoder target data will be one time step ahead as it will not include\n",
    "# the first word i.e 'sos'\n",
    "dec_tr_data = dec_data.reshape(len(dec_data),max_tr_len,1)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session() \n",
    "latent_dim = 500\n",
    " \n",
    "#create input object of total number of encoder words\n",
    "en_inputs = Input(shape=(max_in_len,)) \n",
    "en_embedding = Embedding(num_in_words+1, latent_dim)(en_inputs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 3 stacked LSTM layer with the shape of hidden dimension for text summarizer using deep learning\n",
    "#LSTM 1\n",
    "en_lstm1= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "en_outputs1, state_h1, state_c1= en_lstm1(en_embedding) \n",
    " \n",
    "#LSTM2\n",
    "en_lstm2= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "en_outputs2, state_h2, state_c2= en_lstm2(en_outputs1) \n",
    " \n",
    "#LSTM3\n",
    "en_lstm3= LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "en_outputs3 , state_h3 , state_c3= en_lstm3(en_outputs2)\n",
    " \n",
    "#encoder states\n",
    "en_states= [state_h3, state_c3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder. \n",
    "dec_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(num_tr_words+1, latent_dim) \n",
    "dec_embedding = dec_emb_layer(dec_inputs) \n",
    " \n",
    "#initialize decoder's LSTM layer with the output states of encoder\n",
    "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "dec_outputs, *_ = dec_lstm(dec_embedding,initial_state=en_states) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention =Attention()\n",
    "attn_out = attention([dec_outputs,en_outputs3])\n",
    " \n",
    "#Concatenate the attention output with the decoder outputs\n",
    "merge=Concatenate(axis=-1, name='concat_layer1')([dec_outputs,attn_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense layer (output layer)\n",
    "dec_dense = Dense(num_tr_words+1, activation='softmax') \n",
    "dec_outputs = dec_dense(merge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 64, 500)      156000      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 64, 500),    2002000     ['embedding[0][0]']              \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 64, 500),    2002000     ['lstm[0][0]']                   \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 500)    23500       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 64, 500),    2002000     ['lstm_1[0][0]']                 \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 500),  2002000     ['embedding_1[0][0]',            \n",
      "                                 (None, 500),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 500)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, None, 500)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer1 (Concatenate)    (None, None, 1000)   0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 47)     47047       ['concat_layer1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,234,547\n",
      "Trainable params: 8,234,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "#Model class and model summary for text Summarizer\n",
    "model = Model([en_inputs, dec_inputs], dec_outputs) \n",
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 28s 28s/step - loss: 3.8340 - accuracy: 0.1050 - val_loss: 1.9261 - val_accuracy: 0.7353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    }
   ],
   "source": [
    "model.compile( \n",
    "    optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] ) \n",
    "model.fit( \n",
    "    [en_in_data, dec_in_data],\n",
    "    dec_tr_data, \n",
    "    batch_size=512, \n",
    "    epochs=1, \n",
    "    validation_split=0.1,\n",
    "    )\n",
    " \n",
    "#Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "latent_dim=500\n",
    "#/content/gdrive/MyDrive/Text Summarizer/\n",
    "#load the model\n",
    "model = models.load_model(\"s2s\")\n",
    " \n",
    "#construct encoder model from the output of 6 layer i.e.last LSTM layer\n",
    "en_outputs,state_h_enc,state_c_enc = model.layers[6].output\n",
    "en_states=[state_h_enc,state_c_enc]\n",
    "#add input and state from the layer.\n",
    "en_model = Model(model.input[0],[en_outputs]+en_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "latent_dim=500\n",
    "#/content/gdrive/MyDrive/Text Summarizer/\n",
    "#load the model\n",
    "model = models.load_model(\"s2s\")\n",
    " \n",
    "#construct encoder model from the output of 6 layer i.e.last LSTM layer\n",
    "en_outputs,state_h_enc,state_c_enc = model.layers[6].output\n",
    "en_states=[state_h_enc,state_c_enc]\n",
    "#add input and state from the layer.\n",
    "en_model = Model(model.input[0],[en_outputs]+en_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder inference\n",
    "#create Input object for hidden and cell state for decoder\n",
    "#shape of layer with hidden or latent dimension\n",
    "dec_state_input_h = Input(shape=(latent_dim,))\n",
    "dec_state_input_c = Input(shape=(latent_dim,))\n",
    "dec_hidden_state_input = Input(shape=(max_in_len,latent_dim))\n",
    " \n",
    "# Get the embeddings and input layer from the model\n",
    "dec_inputs = model.input[1]\n",
    "dec_emb_layer = model.layers[5]\n",
    "dec_lstm = model.layers[7]\n",
    "dec_embedding= dec_emb_layer(dec_inputs)\n",
    " \n",
    "#add input and initialize LSTM layer with encoder LSTM states.\n",
    "dec_outputs2, state_h2, state_c2 = dec_lstm(dec_embedding, initial_state=[dec_state_input_h,dec_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention layer\n",
    "attention = model.layers[8]\n",
    "attn_out2 = attention([dec_outputs2,dec_hidden_state_input])\n",
    " \n",
    "merge2 = Concatenate(axis=-1)([dec_outputs2, attn_out2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense layer\n",
    "dec_dense = model.layers[10]\n",
    "dec_outputs2 = dec_dense(merge2)\n",
    "\n",
    "\n",
    " \n",
    "# Finally define the Model Class\n",
    "dec_model = Model(\n",
    "[dec_inputs] + [dec_hidden_state_input,dec_state_input_h,dec_state_input_c],\n",
    "[dec_outputs2] + [state_h2, state_c2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary with a key as index and value as words.\n",
    "reverse_target_word_index = tr_tokenizer.index_word\n",
    "reverse_source_word_index = in_tokenizer.index_word\n",
    "target_word_index = tr_tokenizer.word_index\n",
    "reverse_target_word_index[0]=' '\n",
    " \n",
    "def decode_sequence(input_seq):\n",
    "    #get the encoder output and states by passing the input sequence\n",
    "    en_out, en_h, en_c= en_model.predict(input_seq)\n",
    " \n",
    "    #target sequence with initial word as 'sos'\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_word_index['sos']\n",
    " \n",
    "    #if the iteration reaches the end of text than it will be stop the iteration\n",
    "    stop_condition = True\n",
    "    #append every predicted word in decoded sentence\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition: \n",
    "        #get predicted output, hidden and cell state.\n",
    "        output_words, dec_h, dec_c= dec_model.predict([target_seq] + [en_out,en_h, en_c])\n",
    "        \n",
    "        #get the index and from the dictionary get the word for that index.\n",
    "        word_index = np.argmax(output_words[0, -1, :])\n",
    "        text_word = reverse_target_word_index[word_index]\n",
    "        decoded_sentence += text_word +\" \"\n",
    "        # Exit condition: either hit max length\n",
    "    # or find a stop word or last word.\n",
    "        if text_word == \"eos\" or len(decoded_sentence) > max_tr_len:\n",
    "\n",
    "            stop_condition = True\n",
    "            #update target sequence to the current word index.\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = word_index\n",
    "        en_h, en_c = dec_h, dec_c\n",
    "        #return the decoded sentence\n",
    "        return decoded_sentence\n",
    "        # Exit condition: either hit max length\n",
    "    # or find a stop word or last word.\n",
    "# if text_word == \"eos\" or len(decoded_sentence) > max_tr_len:\n",
    "\n",
    "#     stop_condition = True\n",
    "#     #update target sequence to the current word index.\n",
    "# target_seq = np.zeros((1, 1))\n",
    "# target_seq[0, 0] = word_index\n",
    "# en_h, en_c = dec_h, dec_c\n",
    "# #return the decoded sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit condition: either hit max length\n",
    "    # or find a stop word or last word.\n",
    "if text_word == \"eos\" or len(decoded_sentence) > max_tr_len:\n",
    "\n",
    "    stop_condition = True\n",
    "    #update target sequence to the current word index.\n",
    "target_seq = np.zeros((1, 1))\n",
    "target_seq[0, 0] = word_index\n",
    "en_h, en_c = dec_h, dec_c\n",
    "#return the decoded sentence\n",
    "return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 361ms/step\n",
      "[[177 231 243 158 158 190  10 158   3  61 138  27 190 179  71 138   3 232\n",
      "   13  93 177 110  66  30  71 190 172  30  75 102 190  94  75  66 190   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Prayag Files\\Coding\\Python\\Projects\\textsummariser.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Prayag%20Files/Coding/Python/Projects/textsummariser.ipynb#X44sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m summary\u001b[39m=\u001b[39mdecode_sequence(inp_x\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,max_in_len))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Prayag%20Files/Coding/Python/Projects/textsummariser.ipynb#X44sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(inp_x\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,max_in_len))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Prayag%20Files/Coding/Python/Projects/textsummariser.ipynb#X44sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39;49m\u001b[39meos\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39min\u001b[39;49;00m summary :\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Prayag%20Files/Coding/Python/Projects/textsummariser.ipynb#X44sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m   summary\u001b[39m=\u001b[39msummary\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39meos\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Prayag%20Files/Coding/Python/Projects/textsummariser.ipynb#X44sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mPredicted summary:\u001b[39m\u001b[39m\"\u001b[39m,summary);\u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "inp_review = \"\"\"Every Sharukh Khan release is an event in itself, RAAES is no different. Most of the characters the Khan had been portraying in the recent past have been disappointing to his fanseven the much admired Jahingar Khan of Hello Zindagi was not of much satisfaction due to the limited screen time. And now Raees is something his fans had been waiting and praying that it would tip the balance of fortune towards their much loved star\n",
    "\n",
    "And yes.from the word go, we know a masterpiece is unfolding on the screen. Though the story is not new..a rise and fall of a righteous don has been done to death in Bollywood from times immemorial, but what sets Raees apart is Sharukh Khan, his performance and the amazing screenplay.\n",
    "\n",
    "Jaideep Majumdar (Nawazuddin Siddiqui) reminiscences his tryst with bootlegger Raees (Sharukh Khan) way back in the 90's. Raees story unfolds right from his childhood where he is touchy about his short sight (has to wear glasses) and people calling him \"battery\" due to this impairment. His Ammi (Sheeba Chaddha) is his greatest influence and her words \"business is bigger than religion as long as it does not harm anyone\" remains in his mind and starts working for a local don (Atul Kulkarni).\n",
    "\n",
    "Raees once when he is old enough decides to start his own business and miffs the don and joins hands with a Mumbai don Moosa who funds Raees's bootlegging business.\n",
    "\n",
    "Raees falls in love and gets married to Aasiya (Mahira Khan) and soon becomes a father. His rise disturbs the local don who tries killing Raees and fails and ends up getting killed by him.\n",
    "\n",
    "Jaideep Majumdar, a honest police officer is hot on the trail of Raees and uses every method at his disposal to bring Raees down, but he is unsuccessful as Raees has the support of both the ruling and the opposition party.\n",
    "\n",
    "But soon, Raees's ego makes him a commit one fatal error which turns things in favor of Majumdar..\n",
    "\n",
    "Sharukh is back to doing what he does best, hogging the screen time and also giving one of his career's best performances, his ire when called Battery, or when he is weeping away to glory in his wife's arms after a major setback or his astounding performance in the climax undoubtedly proves the crown is still his.\n",
    "\n",
    "Mahira Khan performs well in what little screen time she has, as the only person who gets away after making fun of Raees's short sight. Wish she had more screen time.\"\"\"\n",
    "\n",
    "inp_review = clean(inp_review,\"inputs\")\n",
    "inp_review = ' '.join(inp_review)\n",
    "# print(\"Review :\",inp_review)\n",
    "\n",
    "inp_x= in_tokenizer.texts_to_sequences([inp_review]) \n",
    "# print(inp_x)\n",
    "inp_x= pad_sequences(inp_x,  maxlen=max_in_len, padding='post')\n",
    "# print(inp_x)\n",
    " \n",
    "summary=decode_sequence(inp_x.reshape(1,max_in_len))\n",
    "print(inp_x.reshape(1,max_in_len))\n",
    "if 'eos' in summary :\n",
    "  summary=summary.replace('eos','')\n",
    "print(\"\\nPredicted summary:\",summary);print(\"summary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee74448ac26aec9e1f090088405c420048a8c66a68ad221e398cf15c498b3fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
